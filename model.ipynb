{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from flask import Flask, request, jsonify, render_template\n",
    "# import pickle\n",
    "# import tensorflow as tf\n",
    "\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# class FastNeuralNetwork:\n",
    "#     def __init__(self, input_size, hidden_size, output_size):\n",
    "#         self.W1 = np.random.randn(input_size, hidden_size) / np.sqrt(input_size)\n",
    "#         self.b1 = np.zeros((1, hidden_size))\n",
    "#         self.W2 = np.random.randn(hidden_size, output_size) / np.sqrt(hidden_size)\n",
    "#         self.b2 = np.zeros((1, output_size))\n",
    "\n",
    "#     def forward(self, X):\n",
    "#         self.z1 = X @ self.W1 + self.b1\n",
    "#         self.a1 = np.maximum(0, self.z1)  # ReLU\n",
    "#         self.z2 = self.a1 @ self.W2 + self.b2\n",
    "#         exp_scores = np.exp(self.z2 - np.max(self.z2, axis=1, keepdims=True))\n",
    "#         self.probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "#         return self.probs\n",
    "\n",
    "#     def backward(self, X, y, output):\n",
    "#         batch_size = X.shape[0]\n",
    "#         d_z2 = output.copy()\n",
    "#         d_z2[range(batch_size), y] -= 1\n",
    "#         d_z2 /= batch_size\n",
    "#         d_W2 = self.a1.T @ d_z2\n",
    "#         d_b2 = np.sum(d_z2, axis=0, keepdims=True)\n",
    "#         d_a1 = d_z2 @ self.W2.T\n",
    "#         d_z1 = d_a1 * (self.z1 > 0)\n",
    "#         d_W1 = X.T @ d_z1\n",
    "#         d_b1 = np.sum(d_z1, axis=0, keepdims=True)\n",
    "#         return d_W1, d_b1, d_W2, d_b2\n",
    "\n",
    "#     def train(self, X, y, epochs=300, batch_size=32, learning_rate=0.1):\n",
    "#         for epoch in range(epochs):\n",
    "#             for i in range(0, X.shape[0], batch_size):\n",
    "#                 X_batch = X[i:i + batch_size]\n",
    "#                 y_batch = y[i:i + batch_size]\n",
    "                \n",
    "#                 output = self.forward(X_batch)\n",
    "#                 d_W1, d_b1, d_W2, d_b2 = self.backward(X_batch, y_batch, output)\n",
    "                \n",
    "#                 self.W1 -= learning_rate * d_W1\n",
    "#                 self.b1 -= learning_rate * d_b1\n",
    "#                 self.W2 -= learning_rate * d_W2\n",
    "#                 self.b2 -= learning_rate * d_b2\n",
    "\n",
    "#             if epoch % 10 == 0:\n",
    "#                 accuracy = self.calculate_accuracy(X, y)\n",
    "#                 print(f\"Epoch {epoch}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "#     def calculate_accuracy(self, X, y):\n",
    "#         predictions = np.argmax(self.forward(X), axis=1)\n",
    "#         return np.mean(predictions == y)\n",
    "\n",
    "#     def predict(self, X):\n",
    "#         return np.argmax(self.forward(X), axis=1)\n",
    "\n",
    "# def process_image(image_file):\n",
    "#     img = Image.open(image_file).convert('RGB').resize((128, 128))\n",
    "#     return np.array(img).flatten() / 255.0\n",
    "\n",
    "# def load_data(data_path):\n",
    "#     image_data = []\n",
    "#     for bird_class in os.listdir(data_path):\n",
    "#         class_path = os.path.join(data_path, bird_class)\n",
    "#         if os.path.isdir(class_path):\n",
    "#             image_data.extend((os.path.join(class_path, img), bird_class) for img in os.listdir(class_path))\n",
    "#     images, labels = zip(*image_data)\n",
    "#     return np.array([process_image(img) for img in images]), np.array(labels)\n",
    "\n",
    "# def save_model(model, label_encoder, model_path):\n",
    "#     with open(model_path, 'wb') as file:\n",
    "#         pickle.dump((model, label_encoder), file)\n",
    "\n",
    "# def load_model(model_path):\n",
    "#     with open(model_path, 'rb') as file:\n",
    "#         model, label_encoder = pickle.load(file)\n",
    "#     return model, label_encoder\n",
    "\n",
    "# # Load and preprocess data\n",
    "# data_path = r\"D:\\Mini project\\New folder\\train\"  # Use raw string literal or use forward slashes\n",
    "# X, y = load_data(data_path)\n",
    "# le = LabelEncoder()\n",
    "# y = le.fit_transform(y)\n",
    "\n",
    "# # Split data\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Create and train model\n",
    "# model = FastNeuralNetwork(input_size=3072, hidden_size=128, output_size=len(le.classes_))\n",
    "# model.train(X_train, y_train, epochs=300, batch_size=64, learning_rate=0.01)\n",
    "\n",
    "# # Save the trained model\n",
    "# os.makedirs(\"backend\", exist_ok=True)\n",
    "# save_model(model, le, \"backend/model.pkl\")\n",
    "\n",
    "# # Load the saved model\n",
    "# loaded_model, loaded_le = load_model(\"backend/model.pkl\")\n",
    "\n",
    "# # Evaluate the loaded model\n",
    "# test_accuracy = loaded_model.calculate_accuracy(X_test, y_test)\n",
    "# print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Accuracy: 0.12\n",
      "Epoch 10, Accuracy: 0.27\n",
      "Epoch 20, Accuracy: 0.23\n",
      "Epoch 30, Accuracy: 0.39\n",
      "Epoch 40, Accuracy: 0.36\n",
      "Epoch 50, Accuracy: 0.31\n",
      "Epoch 60, Accuracy: 0.30\n",
      "Epoch 70, Accuracy: 0.38\n",
      "Epoch 80, Accuracy: 0.31\n",
      "Epoch 90, Accuracy: 0.39\n",
      "Epoch 100, Accuracy: 0.44\n",
      "Epoch 110, Accuracy: 0.44\n",
      "Epoch 120, Accuracy: 0.42\n",
      "Epoch 130, Accuracy: 0.34\n",
      "Epoch 140, Accuracy: 0.36\n",
      "Epoch 150, Accuracy: 0.36\n",
      "Epoch 160, Accuracy: 0.41\n",
      "Epoch 170, Accuracy: 0.44\n",
      "Epoch 180, Accuracy: 0.39\n",
      "Epoch 190, Accuracy: 0.31\n",
      "Epoch 200, Accuracy: 0.39\n",
      "Epoch 210, Accuracy: 0.41\n",
      "Epoch 220, Accuracy: 0.56\n",
      "Epoch 230, Accuracy: 0.47\n",
      "Epoch 240, Accuracy: 0.44\n",
      "Epoch 250, Accuracy: 0.62\n",
      "Epoch 260, Accuracy: 0.45\n",
      "Epoch 270, Accuracy: 0.48\n",
      "Epoch 280, Accuracy: 0.53\n",
      "Epoch 290, Accuracy: 0.47\n",
      "Epoch 300, Accuracy: 0.56\n",
      "Epoch 310, Accuracy: 0.58\n",
      "Epoch 320, Accuracy: 0.52\n",
      "Epoch 330, Accuracy: 0.66\n",
      "Epoch 340, Accuracy: 0.50\n",
      "Epoch 350, Accuracy: 0.61\n",
      "Epoch 360, Accuracy: 0.56\n",
      "Epoch 370, Accuracy: 0.45\n",
      "Epoch 380, Accuracy: 0.61\n",
      "Epoch 390, Accuracy: 0.69\n",
      "Epoch 400, Accuracy: 0.55\n",
      "Epoch 410, Accuracy: 0.50\n",
      "Epoch 420, Accuracy: 0.62\n",
      "Epoch 430, Accuracy: 0.58\n",
      "Epoch 440, Accuracy: 0.64\n",
      "Epoch 450, Accuracy: 0.61\n",
      "Epoch 460, Accuracy: 0.72\n",
      "Epoch 470, Accuracy: 0.58\n",
      "Epoch 480, Accuracy: 0.59\n",
      "Epoch 490, Accuracy: 0.62\n",
      "Epoch 500, Accuracy: 0.66\n",
      "Epoch 510, Accuracy: 0.67\n",
      "Epoch 520, Accuracy: 0.55\n",
      "Epoch 530, Accuracy: 0.67\n",
      "Epoch 540, Accuracy: 0.59\n",
      "Epoch 550, Accuracy: 0.67\n",
      "Epoch 560, Accuracy: 0.59\n",
      "Epoch 570, Accuracy: 0.61\n",
      "Epoch 580, Accuracy: 0.73\n",
      "Epoch 590, Accuracy: 0.64\n",
      "Test Accuracy: 0.61\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from flask import Flask, request, jsonify, render_template\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "class FastNeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) / np.sqrt(input_size)\n",
    "        self.b1 = np.zeros((1, hidden_size))\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) / np.sqrt(hidden_size)\n",
    "        self.b2 = np.zeros((1, output_size))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = X @ self.W1 + self.b1\n",
    "        self.a1 = np.maximum(0, self.z1)  # ReLU\n",
    "        self.z2 = self.a1 @ self.W2 + self.b2\n",
    "        exp_scores = np.exp(self.z2 - np.max(self.z2, axis=1, keepdims=True))\n",
    "        self.probs = exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "        return self.probs\n",
    "\n",
    "    def backward(self, X, y, output):\n",
    "        batch_size = X.shape[0]\n",
    "        d_z2 = output.copy()\n",
    "        d_z2[range(batch_size), y] -= 1\n",
    "        d_z2 /= batch_size\n",
    "        d_W2 = self.a1.T @ d_z2\n",
    "        d_b2 = np.sum(d_z2, axis=0, keepdims=True)\n",
    "        d_a1 = d_z2 @ self.W2.T\n",
    "        d_z1 = d_a1 * (self.z1 > 0)\n",
    "        d_W1 = X.T @ d_z1\n",
    "        d_b1 = np.sum(d_z1, axis=0, keepdims=True)\n",
    "        return d_W1, d_b1, d_W2, d_b2\n",
    "\n",
    "    def train(self, data_generator, steps_per_epoch, epochs=600, learning_rate=0.001):\n",
    "        for epoch in range(epochs):\n",
    "            for step in range(steps_per_epoch):\n",
    "                X_batch, y_batch = next(data_generator)\n",
    "\n",
    "                output = self.forward(X_batch)\n",
    "                d_W1, d_b1, d_W2, d_b2 = self.backward(X_batch, y_batch, output)\n",
    "\n",
    "                self.W1 -= learning_rate * d_W1\n",
    "                self.b1 -= learning_rate * d_b1\n",
    "                self.W2 -= learning_rate * d_W2\n",
    "                self.b2 -= learning_rate * d_b2\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                accuracy = self.calculate_accuracy(X_batch, y_batch)\n",
    "                print(f\"Epoch {epoch}, Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    def calculate_accuracy(self, X, y):\n",
    "        predictions = np.argmax(self.forward(X), axis=1)\n",
    "        return np.mean(predictions == y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.forward(X), axis=1)\n",
    "\n",
    "def process_image(image_file):\n",
    "    img = Image.open(image_file).convert('RGB').resize((128, 128))\n",
    "    return np.array(img).flatten() / 255.0\n",
    "\n",
    "def data_generator(data_path, label_encoder, batch_size=32):\n",
    "    class_dirs = [d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))]\n",
    "    while True:\n",
    "        X_batch, y_batch = [], []\n",
    "        for _ in range(batch_size):\n",
    "            class_dir = np.random.choice(class_dirs)\n",
    "            class_path = os.path.join(data_path, class_dir)\n",
    "            img_file = np.random.choice(os.listdir(class_path))\n",
    "            img_path = os.path.join(class_path, img_file)\n",
    "            X_batch.append(process_image(img_path))\n",
    "            y_batch.append(class_dir)\n",
    "        X_batch = np.array(X_batch)\n",
    "        y_batch = label_encoder.transform(np.array(y_batch))\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "def save_model(model, label_encoder, model_path):\n",
    "    with open(model_path, 'wb') as file:\n",
    "        pickle.dump((model, label_encoder), file)\n",
    "\n",
    "def load_model(model_path):\n",
    "    with open(model_path, 'rb') as file:\n",
    "        model, label_encoder = pickle.load(file)\n",
    "    return model, label_encoder\n",
    "\n",
    "def evaluate_model(model, data_path, label_encoder, batch_size=32, num_batches=100):\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    gen = data_generator(data_path, label_encoder, batch_size=batch_size)\n",
    "    for _ in range(num_batches):\n",
    "        X_batch, y_batch = next(gen)\n",
    "        predictions = model.predict(X_batch)\n",
    "        correct_predictions += np.sum(predictions == y_batch)\n",
    "        total_samples += len(y_batch)\n",
    "    return correct_predictions / total_samples\n",
    "\n",
    "# Load and preprocess data\n",
    "data_path = r\"D:\\mini\\New folder\\Birds_25\\train\"\n",
    "le = LabelEncoder()\n",
    "le.fit([d for d in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, d))])\n",
    "\n",
    "# Split data\n",
    "train_data_path = r\"D:\\mini\\New folder\\Birds_25\\train\"\n",
    "test_data_path = r\"D:\\mini\\New folder\\Birds_25\\valid\"\n",
    "\n",
    "# Create and train model\n",
    "input_size = 128 * 128 * 3\n",
    "hidden_size = 128\n",
    "output_size = len(le.classes_)\n",
    "model = FastNeuralNetwork(input_size, hidden_size, output_size)\n",
    "\n",
    "batch_size = 64\n",
    "steps_per_epoch = 100  # Adjust according to your data size\n",
    "data_gen = data_generator(train_data_path, le, batch_size)\n",
    "model.train(data_gen, steps_per_epoch, epochs=600, learning_rate=0.001)\n",
    "\n",
    "# Save the trained model\n",
    "os.makedirs(\"backend\", exist_ok=True)\n",
    "save_model(model, le, \"backend/model.pkl\")\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model, loaded_le = load_model(\"backend/model.pkl\")\n",
    "\n",
    "# Evaluate the loaded model\n",
    "test_accuracy = evaluate_model(loaded_model, test_data_path, loaded_le, batch_size, num_batches=100)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
